{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060e7a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd37735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI (model =\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a57c5ad",
   "metadata": {},
   "source": [
    "# Buffer Memory\n",
    "\n",
    "* ConversationBufferMemory keeps a list of chat messages in a buffer and passes those into the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fea207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caner\\AppData\\Local\\Temp\\ipykernel_21316\\3337314558.py:21: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "C:\\Users\\caner\\AppData\\Local\\Temp\\ipykernel_21316\\3337314558.py:23: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0458035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caner\\AppData\\Local\\Temp\\ipykernel_21316\\2596321432.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  conversation({\"question\": \"hi\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'hi',\n",
       " 'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Hello! How are you today?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e617ea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Caner and I'm 23 yo\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"My name is Caner and I'm 23 yo\",\n",
       " 'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"My name is Caner and I'm 23 yo\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Caner! Is there anything you'd like to talk about or any questions you have?\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"Nice to meet you, Caner! Is there anything you'd like to talk about or any questions you have?\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"My name is Caner and I'm 23 yo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a0b33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Caner and I'm 23 yo\n",
      "AI: Nice to meet you, Caner! Is there anything you'd like to talk about or any questions you have?\n",
      "Human: In a running race, if you overtake the 2nd place, what position are you in?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'In a running race, if you overtake the 2nd place, what position are you in?',\n",
       " 'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"My name is Caner and I'm 23 yo\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Caner! Is there anything you'd like to talk about or any questions you have?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='In a running race, if you overtake the 2nd place, what position are you in?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='If you overtake the 2nd place in a running race, you would then be in the 2nd place.', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'If you overtake the 2nd place in a running race, you would then be in the 2nd place.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"In a running race, if you overtake the 2nd place, what position are you in?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9903a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Caner and I'm 23 yo\n",
      "AI: Nice to meet you, Caner! Is there anything you'd like to talk about or any questions you have?\n",
      "Human: In a running race, if you overtake the 2nd place, what position are you in?\n",
      "AI: If you overtake the 2nd place in a running race, you would then be in the 2nd place.\n",
      "Human: Which informations u know about me ?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Which informations u know about me ?',\n",
       " 'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"My name is Caner and I'm 23 yo\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Caner! Is there anything you'd like to talk about or any questions you have?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='In a running race, if you overtake the 2nd place, what position are you in?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='If you overtake the 2nd place in a running race, you would then be in the 2nd place.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Which informations u know about me ?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I know that your name is Caner and you are 23 years old based on what you've shared with me in this conversation. If you would like to share more about yourself or ask any questions, feel free to do so!\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"I know that your name is Caner and you are 23 years old based on what you've shared with me in this conversation. If you would like to share more about yourself or ask any questions, feel free to do so!\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"Which informations u know about me ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db85744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Caner and I'm 23 yo\n",
      "AI: Nice to meet you, Caner! Is there anything you'd like to talk about or any questions you have?\n",
      "Human: In a running race, if you overtake the 2nd place, what position are you in?\n",
      "AI: If you overtake the 2nd place in a running race, you would then be in the 2nd place.\n",
      "Human: Which informations u know about me ?\n",
      "AI: I know that your name is Caner and you are 23 years old based on what you've shared with me in this conversation. If you would like to share more about yourself or ask any questions, feel free to do so!\n",
      "Human: What you think my job is ??\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What you think my job is ??',\n",
       " 'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"My name is Caner and I'm 23 yo\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Caner! Is there anything you'd like to talk about or any questions you have?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='In a running race, if you overtake the 2nd place, what position are you in?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='If you overtake the 2nd place in a running race, you would then be in the 2nd place.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Which informations u know about me ?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I know that your name is Caner and you are 23 years old based on what you've shared with me in this conversation. If you would like to share more about yourself or ask any questions, feel free to do so!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What you think my job is ??', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm not able to accurately guess your job, but if you'd like to share what you do for a living, I'd be happy to learn more about you!\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"I'm not able to accurately guess your job, but if you'd like to share what you do for a living, I'd be happy to learn more about you!\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"What you think my job is ??\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5527adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"My name is Caner and I'm 23 yo\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, Caner! Is there anything you'd like to talk about or any questions you have?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='In a running race, if you overtake the 2nd place, what position are you in?', additional_kwargs={}, response_metadata={}), AIMessage(content='If you overtake the 2nd place in a running race, you would then be in the 2nd place.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Which informations u know about me ?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I know that your name is Caner and you are 23 years old based on what you've shared with me in this conversation. If you would like to share more about yourself or ask any questions, feel free to do so!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What you think my job is ??', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm not able to accurately guess your job, but if you'd like to share what you do for a living, I'd be happy to learn more about you!\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa65690",
   "metadata": {},
   "source": [
    "# Conversation Buffer Window Memory\n",
    "\n",
    "* Similar to the previous one, but you can limit the number of conversational exchanges stored in memory. For example, you can set it so it only remembers the last 3 questions and answers of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25b0e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4413be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35c70814",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d308522",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_window = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=prompt,\n",
    "    memory=window_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55918732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Hi, my name is Caner\n",
      "AI: Hello Caner, nice to meet you! How can I assist you today?\n",
      "Human: my fav animal is dog , how about u ?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'my fav animal is dog , how about u ?', 'chat_history': [HumanMessage(content='Hi, my name is Caner', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello Caner, nice to meet you! How can I assist you today?', additional_kwargs={}, response_metadata={})], 'text': \"As an AI assistant, I don't have personal preferences or feelings, but dogs are definitely a popular and beloved animal by many! They are loyal, playful, and wonderful companions. What do you love most about dogs?\"}\n"
     ]
    }
   ],
   "source": [
    "result = conversation_window.invoke({\"question\": \"my fav animal is dog , how about u ?\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "025b10f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Hi, my name is Caner\n",
      "AI: Hello Caner, nice to meet you! How can I assist you today?\n",
      "Human: my fav animal is dog , how about u ?\n",
      "AI: As an AI assistant, I don't have personal preferences or feelings, but dogs are definitely a popular and beloved animal by many! They are loyal, playful, and wonderful companions. What do you love most about dogs?\n",
      "Human: {'What is my name'}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': {'What is my name'},\n",
       " 'chat_history': [HumanMessage(content='Hi, my name is Caner', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello Caner, nice to meet you! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='my fav animal is dog , how about u ?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"As an AI assistant, I don't have personal preferences or feelings, but dogs are definitely a popular and beloved animal by many! They are loyal, playful, and wonderful companions. What do you love most about dogs?\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Your name is Caner. How can I assist you further today?'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window.invoke({\"What is my name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af36472",
   "metadata": {},
   "source": [
    "# Chat Message History\n",
    "\n",
    "* save list of chat messages and then fetch them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "970d0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62a7007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1afd383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='whats up?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5254f97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
