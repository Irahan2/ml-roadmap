{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400a1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (API keys, etc.) from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8966380",
   "metadata": {},
   "source": [
    "## Completion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a816b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Completion model\n",
    "from langchain_openai import OpenAI\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284fa679",
   "metadata": {},
   "source": [
    "## Chat Copmletion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe3d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Completion model\n",
    "from langchain_openai import ChatOpenAI\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c3edb",
   "metadata": {},
   "source": [
    "## Prompts and Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b8858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "It was a hot summer day in June when the news broke that left the entire world in shock. Michael Jackson, the King of Pop, had passed away. The streets were flooded with fans crying and holding onto each other for comfort. It was hard to believe that the man who had been entertaining us for decades was no longer with us.\n",
      "\n",
      "The details of his death were still unclear, but rumors were swirling that he had suffered a heart attack. As fans gathered outside his home in Los Angeles, the news finally broke that Michael Jackson had died from a drug overdose. The whole world was in disbelief. How could this happen to someone so talented and loved by millions?\n",
      "\n",
      "As the news spread, people all over the world started to pay tribute to the fallen legend. Radio stations played his songs non-stop, and his albums shot to the top of the charts. Social media was flooded with pictures and videos of his iconic performances, and everyone shared their favorite memories of the King of Pop.\n",
      "\n",
      "In the midst of the mourning, a group of fans in New York City came up with a wild idea. They wanted to honor Michael Jackson by recreating his famous dance routine from the music video \"Thriller.\" They spread the word on social media, and soon enough, hundreds of people showed\n"
     ]
    }
   ],
   "source": [
    "# This is for completions model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a {adjective}story about {topic}\")\n",
    "\n",
    "llmModelPrompt = prompt_template.format(\n",
    "    adjective = \"excited\",\n",
    "    topic = \" How Michael Jackson died ?  \"\n",
    ")\n",
    "\n",
    "res = llmModel.invoke(llmModelPrompt)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54599b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Certainly! The most successful club in Premier League history is Manchester United. As of the 2021-2022 season, Manchester United has won the Premier League title 13 times since its inception in 1992. They have also achieved a remarkable treble in the 1998-1999 season, winning the Premier League, FA Cup, and UEFA Champions League. Manchester United's success in the Premier League is a significant part of their storied history as one of the most successful clubs in English football.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 62, 'total_tokens': 165, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CBapaelCrpNj7g6NbWAbVYM59zDOG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--ef134cd9-a3fc-45c8-a951-64bc58b12e0d-0' usage_metadata={'input_tokens': 62, 'output_tokens': 103, 'total_tokens': 165, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# chat completion model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a {profession} expert on the {topic}.\"),\n",
    "        (\"human\", \"Hello, Mr. {profession}, can you please answer a question?\"),\n",
    "        (\"ai\", \"Sure!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession=\"football expert\",\n",
    "    topic=\"the English Premier League\",\n",
    "    user_input=\"Can you tell me about the most successful club in Premier League history?\"\n",
    ")\n",
    "\n",
    "\n",
    "response = chatModel.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b681df5",
   "metadata": {},
   "source": [
    "## Old Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9582591c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Certainly! The most successful club in Premier League history is Manchester United. They have won a total of 13 Premier League titles since the league was formed in 1992. Under the legendary manager Sir Alex Ferguson, Manchester United dominated English football for many years and established themselves as one of the most successful clubs in the world. Their success in the Premier League has been built on a combination of talented players, strong team spirit, and a winning mentality.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 36, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CBarbMLdUCxUYWaxYCoKYVhdmjL2f', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f5775152-c544-4a6e-86f4-c6483c4bfe63-0' usage_metadata={'input_tokens': 36, 'output_tokens': 90, 'total_tokens': 126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a football expert on the English Premier League.\"\n",
    "            ),\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    user_input=\"Can you tell me about the most successful club in Premier League history?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ce9960",
   "metadata": {},
   "source": [
    "## Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bef661c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"¡adiós!\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa557e5",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd017c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cómo va todo?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"¡adiós!\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chatModel\n",
    "\n",
    "res= chain.invoke({\"input\": \"How is going\"})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54905908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Langchain Expression Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab62fb",
   "metadata": {},
   "source": [
    "## Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d58ce263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7ac9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5013f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Warsaw'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "llmModel = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) \n",
    "\n",
    "\n",
    "json_chain = json_prompt | llmModel | json_parser\n",
    "\n",
    "question_to_ask = \"What is the capital of Poland?\"\n",
    "result = json_chain.invoke({\"question\": question_to_ask})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0eb6a0",
   "metadata": {},
   "source": [
    "Optionally , We can use Pydantic to define a custom output format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f96e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36ece642",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3f4bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caner\\anaconda3\\envs\\llmapp\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='question to set up a joke' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "c:\\Users\\caner\\anaconda3\\envs\\llmapp\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='answer to resolve the joke' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'It was two tired.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parser referring the Pydantic Object\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Add the parser format instructions in the prompt definition.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Create a chain with the prompt and the parser\n",
    "chain = prompt | chatModel | parser\n",
    "\n",
    "chain.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
